{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Germany Universities\n",
    "\n",
    "#importing necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#setting up headless Firefox browser\n",
    "firefox_options = Options()\n",
    "firefox_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "\n",
    "\n",
    "base_url = \"https://collegedunia.com/germany-universities\"\n",
    "for i in range(1,2):\n",
    "  college_list = []\n",
    "  url = base_url\n",
    "  #  + f\"{i}\"\n",
    "  print(url)\n",
    "  driver.get(url)\n",
    "  # print(driver)\n",
    "  # driver.implicitly_wait(2)\n",
    "\n",
    "  # for j in range(2):\n",
    "  #     driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "  #     time.sleep(1)\n",
    "\n",
    "  #get HTML source and parse with BeautifulSoup\n",
    "  soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "  field = soup.find(\"table\", class_ = \"jsx-4182613765 table listing-table\")\n",
    "  # print(field)\n",
    "  college_elements = field.find_all(\"tr\", class_ = \"jsx-3040859135 automate_client_img_snippet\")\n",
    "  print(len(college_elements))\n",
    "\n",
    "  for count, element in enumerate(college_elements):\n",
    "      print(count)\n",
    "      soup2 = BeautifulSoup(str(element), \"html.parser\")\n",
    "      slug = \"https://collegedunia.com\" + soup2.find(\"a\")[\"href\"]\n",
    "      university_name = soup2.find(\"span\", class_ = \"jsx-3040859135 clg-title-wrapper d-flex align-items-start justify-content-start mb-1\").text\n",
    "      region = soup2.find(\"span\", class_ = \"jsx-3040859135 text-gray text-md mr-2 text-capitalize\").text\n",
    "      try:\n",
    "        ranking = soup2.find('span', class_ = \"jsx-3040859135 rating-rank d-flex flex-column has-no-review\").text\n",
    "      except:\n",
    "        ranking = \"\"\n",
    "      try:\n",
    "        rate = soup2.find('span', class_ = \"jsx-3040859135 bg-gray font-weight-bold text-black mr-1 rounded-sm\").text\n",
    "      except:\n",
    "        rate = \"\"\n",
    "      try:\n",
    "        fee = soup2.find(\"span\", class_ = \"jsx-3040859135 font-weight-bold text-success\").text\n",
    "      except:\n",
    "        fee = \"\"\n",
    "      country = \"Germany\"\n",
    "      year = students = international_students = ratio = faculty_count = total_schools = \"\"\n",
    "      logo_url = \"https://leapscholar.com\" + soup2.find(\"img\")[\"src\"]\n",
    "      url = slug\n",
    "      driver.get(url)\n",
    "      driver.implicitly_wait(1)\n",
    "      for k in range(1):\n",
    "        driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      field = soup.find(\"div\", class_ = \"cdcms_college_highlights\")\n",
    "      soup2 = BeautifulSoup(str(field), \"html.parser\")\n",
    "      table_dict = dict()\n",
    "      ele_list = soup2.find_all(\"tr\")\n",
    "      try:\n",
    "        for ele in ele_list:\n",
    "          table_dict.update({ele.find_all(\"td\")[0].text:ele.find_all(\"td\")[-1].text})\n",
    "      except:\n",
    "        table_dict = dict()\n",
    "      if \"Number of campuses\" in table_dict:\n",
    "        total_schools = table_dict[\"Number of campuses\"]\n",
    "      if \"Established\" in table_dict:\n",
    "        year = table_dict[\"Established\"]\n",
    "      if \"Foundation Year\" in table_dict:\n",
    "        year = table_dict[\"Foundation Year\"]\n",
    "      if \"Total enrolment\" in table_dict:\n",
    "        students = table_dict[\"Total enrolment\"]\n",
    "      if \"Total Student Enrolment\" in table_dict:\n",
    "        students = table_dict[\"Total Student Enrolment\"]\n",
    "      if \"International students\" in table_dict:\n",
    "        international_students = table_dict[\"International students\"]\n",
    "      if \"Faculties\" in table_dict:\n",
    "        faculty_count = table_dict[\"Faculties\"]\n",
    "      if \"Faculty\" in table_dict:\n",
    "        faculty_count = table_dict[\"Faculty\"]\n",
    "      if \"Total Faculties\" in table_dict:\n",
    "        faculty_count = table_dict[\"Total Faculties\"]\n",
    "      if \"Academic Faculty\" in table_dict:\n",
    "        faculty_count = table_dict[\"Academic Faculty\"]\n",
    "      if \"Academic staff\" in table_dict:\n",
    "        faculty_count = table_dict[\"Academic staff\"]\n",
    "      # try:\n",
    "      #     overview = \"\"\n",
    "      #     for ele in table_dict:\n",
    "      #       overview += ele.text\n",
    "      # except (AttributeError, IndexError):\n",
    "      #   print(\"nope\")\n",
    "      #   overview = \"\"\n",
    "      college_list.append([university_name, country, region, fee, ranking, year, logo_url, slug, students, international_students, ratio, faculty_count, rate, total_schools])\n",
    "\n",
    "#quit WebDriver\n",
    "driver.quit()\n",
    "\n",
    "#write data to CSV file\n",
    "with open('Germany_Universities.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    #write header row\n",
    "    writer.writerow(['University Name', 'Country', 'Region', 'Fees', 'Ranking', 'Established on', 'University Logo', 'University Link', 'Total Number of Students', 'Total Number of International Students', 'Student-Faculty Ratio', 'Faculty Count', 'Acceptance Rate', 'Total Schools'])\n",
    "    #write each job posting as a separate row\n",
    "    for job in college_list:\n",
    "        writer.writerow(job)\n",
    "\n",
    "print(\"CSV file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Germany Universities 2nd part\n",
    "\n",
    "#importing necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#setting up headless Firefox browser\n",
    "firefox_options = Options()\n",
    "firefox_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "\n",
    "\n",
    "base_url = \"https://collegedunia.com/germany-universities\"\n",
    "for i in range(1,2):\n",
    "  college_list = []\n",
    "  url = base_url\n",
    "  #  + f\"{i}\"\n",
    "  print(url)\n",
    "  driver.get(url)\n",
    "  # print(driver)\n",
    "  driver.implicitly_wait(2)\n",
    "\n",
    "  for j in range(2):\n",
    "      driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "      time.sleep(1)\n",
    "\n",
    "  #get HTML source and parse with BeautifulSoup\n",
    "  soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "  field = soup.find(\"table\", class_ = \"jsx-4182613765 table listing-table\")\n",
    "  # print(field)\n",
    "  college_elements = field.find_all(\"tr\", class_ = \"jsx-3040859135 automate_client_img_snippet\")\n",
    "  print(len(college_elements))\n",
    "\n",
    "  for count, element in enumerate(college_elements):\n",
    "      print(count)\n",
    "      soup2 = BeautifulSoup(str(element), \"html.parser\")\n",
    "      slug = \"https://collegedunia.com\" + soup2.find(\"a\")[\"href\"]\n",
    "      url = slug\n",
    "      driver.get(url)\n",
    "      driver.implicitly_wait(1)\n",
    "      for k in range(1):\n",
    "        driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      # Wait for the \"Read More\" button to be clickable\n",
    "      wait = WebDriverWait(driver, 10)\n",
    "      read_more_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@data-csm-title='SHOW LESS']\")))\n",
    "      # Click the \"Read More\" button\n",
    "      read_more_button.click()\n",
    "      description = \"\"\n",
    "      try:\n",
    "        des_list = soup.find(\"div\", class_ = \"cdcms_college_highlights\").find_all(\"p\")\n",
    "        for ele in des_list:\n",
    "          description += ele.text\n",
    "      except:\n",
    "        description = \"\"\n",
    "      banner = soup.find(\"img\", class_ = \"jsx-4244687402 banner\")[\"src\"]\n",
    "      logo_url = soup.find(\"img\", class_ = \"jsx-780138922 rounded p-1\")[\"src\"]\n",
    "      url = url + \"/programs\"\n",
    "      driver.get(url)\n",
    "      driver.implicitly_wait(1)\n",
    "      for k in range(1):\n",
    "        driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      courses_list = soup.find_all(\"div\", class_ = \"jsx-2492516079 jsx-2133140133 card-head-left\")\n",
    "      courses = \"\"\n",
    "      for course_count, ele in enumerate(courses_list):\n",
    "        courses += f'{course_count + 1}) {ele.text}\\n'\n",
    "      college_list.append([description, banner, logo_url, courses])\n",
    "\n",
    "#quit WebDriver\n",
    "driver.quit()\n",
    "\n",
    "#write data to CSV file\n",
    "with open('Germany_Universities 2nd part.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    #write header row\n",
    "    writer.writerow(['Description', 'Banner', 'University Logo', 'Courses'])\n",
    "    #write each job posting as a separate row\n",
    "    for job in college_list:\n",
    "        writer.writerow(job)\n",
    "\n",
    "print(\"CSV file created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Germany Universities 2nd part\n",
    "\n",
    "#importing necessary libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "#setting up headless Firefox browser\n",
    "firefox_options = Options()\n",
    "firefox_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "\n",
    "# college_list = []\n",
    "base_url = \"https://collegedunia.com/germany-universities/page-\"\n",
    "for i in range(2,4):\n",
    "  url = base_url + f\"{i}\"\n",
    "  #  + f\"{i}\"\n",
    "  print(url)\n",
    "  driver.get(url)\n",
    "  # print(driver)\n",
    "  driver.implicitly_wait(2)\n",
    "\n",
    "  for j in range(2):\n",
    "      driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "      time.sleep(1)\n",
    "\n",
    "  #get HTML source and parse with BeautifulSoup\n",
    "  soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "  field = soup.find(\"table\", class_ = \"jsx-4182613765 table listing-table\")\n",
    "  # print(field)\n",
    "  college_elements = field.find_all(\"tr\", class_ = \"jsx-3040859135 automate_client_img_snippet\")\n",
    "  print(len(college_elements))\n",
    "\n",
    "  for count, element in enumerate(college_elements):\n",
    "      print(count)\n",
    "      soup2 = BeautifulSoup(str(element), \"html.parser\")\n",
    "      slug = \"https://collegedunia.com\" + soup2.find(\"a\")[\"href\"]\n",
    "      url = slug\n",
    "      driver.get(url)\n",
    "      driver.implicitly_wait(1)\n",
    "      for k in range(1):\n",
    "        driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      # Wait for the \"Read More\" button to be clickable\n",
    "      wait = WebDriverWait(driver, 10)\n",
    "      read_more_button = wait.until(EC.element_to_be_clickable((By.XPATH, \"//div[@data-csm-title='SHOW LESS']\")))\n",
    "      # Click the \"Read More\" button\n",
    "      read_more_button.click()\n",
    "      description = \"\"\n",
    "      try:\n",
    "        des_list = soup.find(\"div\", class_ = \"cdcms_college_highlights\").find_all(\"p\")\n",
    "        for ele in des_list:\n",
    "          description += ele.text\n",
    "      except:\n",
    "        description = \"\"\n",
    "      banner = soup.find(\"img\", class_ = \"jsx-4244687402 banner\")[\"src\"]\n",
    "      logo_url = soup.find(\"img\", class_ = \"jsx-780138922 rounded p-1\")[\"src\"]\n",
    "      url = url + \"/programs\"\n",
    "      driver.get(url)\n",
    "      driver.implicitly_wait(1)\n",
    "      for k in range(1):\n",
    "        driver.execute_script(\"window.scrollTo(0,0.95*document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "      soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "      courses_list = soup.find_all(\"div\", class_ = \"jsx-2492516079 jsx-2133140133 card-head-left\")\n",
    "      courses = \"\"\n",
    "      for course_count, ele in enumerate(courses_list):\n",
    "        courses += f'{course_count + 1}) {ele.text}\\n'\n",
    "      college_list.append([description, banner, logo_url, courses])\n",
    "\n",
    "#quit WebDriver\n",
    "driver.quit()\n",
    "\n",
    "#write data to CSV file\n",
    "with open('Germany_Universities 2nd part 2.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    #write header row\n",
    "    writer.writerow(['Description', 'Banner', 'University Logo', 'Courses'])\n",
    "    #write each job posting as a separate row\n",
    "    for job in college_list:\n",
    "        writer.writerow(job)\n",
    "\n",
    "print(\"CSV file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
